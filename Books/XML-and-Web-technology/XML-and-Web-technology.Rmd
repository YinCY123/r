---
title: "XML-and-Web-technology"
author: "yincy"
date: "7/2/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, message=FALSE, warning=FALSE}
library(XML)
library(rjson)
library(tidyverse)
```


# Chapter 1 Getting Started with XML and JSON  
## Reading from HTMLTables  
```{r}
u <- "/home/yincy/git/R-codes/Books/XML-and-Web-technology/files/List of countries and dependencies by population - Wikipedia.html"
tbls <- readHTMLTable(doc = u)
tbls %>% class()
```

```{r}
sapply(tbls, names)
sapply(tbls, nrow) # the large table is the population table
```

```{r}
pop <- readHTMLTable(doc = u, 
                     which = 1, 
                     header = T)
colnames(pop) <- c("Rank", "Country", "Population", "Percentage", "Date", "Source")
pop %>% head()
```


For each <table> node, `readHTMLTable()` loops over the row nodes (<tr>) and processes each cell in the row. These cells are either <th> or <td> elements for header or regular data, respectively.  

The data are typically in <td> elements, and we simply extract the contents of each cell as string.  

The <th> elements in a table typically indicate column header, and is used for variable names when appropriate.  


# Chapter 3 Parsing XML Content  
```{r}
doc <- xmlParse("Data/Kiva/lenders/")
lenderNode <- xmlRoot(doc)[["lenders"]]
occ <- sapply(xmlChildren(lenderNode), function(node) {
    xmlValue(node[["occupation"]])
}) %>% table() %>% sort(decreasing = T)
```


```{r}
doc <- xmlParse(file = "Data/merged_catalog.xml.gz")
root <- xmlRoot(x = doc)
xmlName(root)
```

```{r}
root %>% xmlSize()
```

```{r}
xmlChildren(root) %>% length()
```

```{r}
event1 <- root[["event"]]
event1
```

```{r}
event1[[10]] %>% xmlAttrs() %>% .["value"]
```

```{r}
root[1:3]
```

```{r}
evs <- root["event"]
length(evs)
root[names(root) == "event"]
```


```{r}
names(event1) # node names of the child elements
```

```{r}
xmlName(event1) # node names of the node itself
``` 

```{r}
doc <- xmlParse(file = "Data/Kiva/lenders/1.xml")
lenderNode <- xmlRoot(doc)[["lenders"]]
xmlSize(lenderNode)
```

```{r}
lenderNode
lenderNode[[1]][c("name", "occupation", "image", "country_code")]
```

```{r}
lenderNode[[1]][c("name", "image", "whereabouts", "country_code")]
```

```{r}
w <- sapply(xmlChildren(lenderNode[[1]]), xmlSize) > 1
lenderNode[[1]][w]
```


```{r}
doc <- xmlParse(file = "Data/merged_catalog.xml.gz")
root <- xmlRoot(x = doc)

timests <- xmlSApply(X = root, xmlGetAttr, name = "time-stamp")
timests %>% class()
timests[[1]]
```

```{r}
xmlSApply(X = root, xmlGetAttr, name = "id")
```

```{r}
child10 <- xmlSApply(root, "[[", 10) %>% sapply(X = ., xmlGetAttr, name = "value")
names(child10) <- NULL
table(child10) %>% barplot()
```

```{r}
xmlSApply(root, xmlSize)[1:4]
```

more general approch to ge magnitude  
```{r}
mags <- xmlSApply(root, function(evNode){
    parNames = xmlSApply(evNode, xmlGetAttr, "name")
    i = which(parNames == "magnitude")
    xmlGetAttr(evNode[[i]], name = "value")
})
```

```{r}
mags <- getNodeSet(doc = root, 
           path = "/merge/event/param[@name='magnitude']/@value") %>% 
    unlist() %>% 
    as.numeric()

time_stamp <- getNodeSet(doc = root, 
                         path = "/merge/event[@version = '1']") %>% 
    xmlSApply(xmlGetAttr, name = "time-stamp")

mags %>% table() %>% barplot()
```


```{r}
# do not lost access to the parent even though we assigned this node to a new variable.  
firstMag <- root[[1]][[10]]

getSibling(node = firstMag, after = T)
```


```{r}
xmlParent(firstMag) %>% getSibling(after = TRUE) %>% xmlAttrs()
```


```{r}
xmlAncestors(x = firstMag)[[1]] %>% xmlName()
```

```{r}
firstMag %>% xmlParent() %>% getSibling(after = T) %>% .[[10]]
```

```{r}
root[2]
```


**The DOM Parser in R**  

read the XML document into R  
```{r}
doc <- xmlParse(file = "Data/sampleDoc.xml")
```

Access the root node  
```{r}
root <- xmlRoot(x = doc)
```

Operate on a node as if it is a list of its children, i.e. use `[` and `[[` to access elements in the tree.  
```{r}
node3_1 <- root[[3]][[1]]
node3_1 <- root[["section"]][["para"]]
```

The `XML` package provides functions for determining information about a node. These include `xmlName()`, `xmlSize()`, `xmlAttrs()`, `xmlGetAttr()`, `xmlValue`, `xmlNamespace()` and `getDefaultNamespace()`, which provide, in order, the node's name, number of children, attributes, a specific attribute, text content of the node and its descendants, namespace, and defualt namespace.  
```{r}
root[["title"]] %>% xmlValue()
root[["section"]] %>% xmlValue()
```

In addition to `[` and `[[`, other functions in XML enables us to work with a node's aiblings, children, parent and acncestors. These are `getSibling()`, `xmlChildren()`, `xmlParent()`, and `xmlAncestors()`, respectively.  
```{r}
node3_1 %>% xmlParent()
```

```{r}
getSibling(node = root[[2]])
```

```{r}
node3_1 %>% xmlParent() %>% xmlParent() %>% .[[1]]

# equal to the root[[1]]
root[[1]]
```

```{r}
node3_1 %>% xmlParent() %>% getSibling(after = F) %>% getSibling(after = F)
```

The tree object behaves differently from regular R objects. When we make the assignment, `node3_1 == root[[3]][[1]]`, we now have a reference to that point in the tree. Any operations on `node3_1` will be made to the tree as well.  
```{r}
node3_1 = root[[3]][[1]]
node3_1 %>% xmlParent() %>% xmlParent()
```


## Parsing Other XML Element Types  
```{r}
rdbRoot <- xmlParse(file = "Data/sampleDoc.xml") %>% xmlRoot()

rdbRoot[[2]]
```

```{r}
rdbRoot[[2]] %>% xmlValue()
```

The `xmlValue()` function is generic so it it works on different types of nodes. For nodes that are mixtures of text content and other nodes, `xmlValue()` returns a character string that concatenates the text content of all the node's descendants.  
```{r}
rdbRoot[[3]][[1]] %>% names()
```

```{r}
rdbRoot[[3]][[1]] %>% 
    xmlChildren() %>% 
    sapply(class)
```

```{r}
rdbRoot[[3]][[1]] %>% 
    xmlSApply(xmlValue)
```

```{r}
rdbRoot[[3]][[1]] %>% 
    xmlNamespace()


rdbRoot[[3]][[1]] %>% 
    getDefaultNamespace()
```


## Reading XML from Different Input Sources  
The parser available through the `XML` package supports reading local files, in-memory XML strings, URLs, and 'local' compressed files.  
```{r}
xmlParse(file = "https://sports.sohu.com/s/nba", isHTML = T)
```

 
```{r}
getEncoding(obj = rdbRoot)
```


# Chapter 4 XPath, XPointer, and XInclude  
```{r}
doc <- htmlParse(file = "http://www.bioconductor.org/packages/release/bioc/vignettes/TCGAbiolinks/inst/doc/subtypes.html")
listOfNodes <- getNodeSet(doc = doc, path = "//a[@href]")
```

```{r}
xpathSApply(doc, path = "//a[@href]", fun = xmlGetAttr, name = "href") %>% head()
```

```{r}
getNodeSet(doc, path = "//a/@href") %>% .[10:20]
```


```{r}
mil <- xmlParse(file = "files/sweat_metabolites.xml")

mol <- getNodeSet(doc = mil, path = "/*/metabolite/accession/text()")
xpexpr <- ".//metabolite/accession/text()"
lapply(mil, function(node) xpathSApply(node, xpexpr, xmlValue))
```


## XPath and the XML Tree  
```{r}
doc <- xmlParse(file = "Data/eurofxref-hist.xml")
root <- xmlRoot(x = doc)
root %>% xmlSize()
```

```{r}
xpexpr <- "/Envelope/Sender/name"
nm <- getNodeSet(doc = root, path = xpexpr)
nm %>% xmlToDataFrame()
```

```{r}
mn <- getNodeSet(doc = root, path = "//Cube[@currency = 'JPY']")
mn %>% xmlToDataFrame()
```

```{r}
getNodeSet(doc = doc, path = "//Cube[@currency = 'CZK' and @rate < 25]")
```


## XPath Syntax  
An XPath expression is made up of one or more location steps, separated by a / character. An individual location step has three distinct parts, the axis, node-test, and an optional predicate, which we specify in the following format:  
```
axis::node-test[predicate]
```

### The Axis  
The axis provides both the direction to look for nodes (from the current context) and also how to look along that direction. Directions are expressed using the family relationship terminology from the document hierarchy, e.g., child, parent, sibling, ancestor, desendant.  

The `child` axis looks down the tree one level (from the current location or context) to the immediate child nodes.  

The `parent` and `ancestor` axes look up the node while the `ancestor` looks at the parent node, the parent's parent, and so on up to the root node.  

The ancestor-or-self axis considers all the ancestor as well as the current node (the current node is the `self` axis).  

Similarly, `descendant` and `descendant-or-self` work on descendant elements in the tree.  

The `preceding-sibling` and `following-sibling` look along the same level of the current context at all of the preceding siblings (to the left) and the following siblings (to the right), respectively.  


#### Axis Shortcuts and Abbreviations  
Some axes are very common so there are shortcuts for these that make the XPath expression more succinct and clearer to read. These shortcuts can be used in a location step within the location path. The most common axis is child. This is the default axis and can be omitted from any XPath step.  

Another commonly used abbreviation is the double forward slash `//` which is shorthand for the axis `descendant-or-self`.  

```
/child::Envelope/child::Cube/child::Cube/child::Cube
```

It can also be writen as  
```
/Envelope/Cube/Cube/Cube
```

```{r}
root <- xmlRoot(mil)

root %>% xmlSize()
root %>% xmlSApply(xmlValue)
getNodeSet(doc, "//Envelope")
```


#### The Node Test  
The node-test component in a location step identifies the name or the type of node to be matched. This is often just simply the name of the nodes in which we are interested, e.g., Cube, Sender, or molecule.  

At times we want to match a node with any name, and not a specific fixed name. In this case we can use the asterisk (*) as a wildcard that matches all named elements.  

The * symbol is realy shorthand for the `node()` function that matches any regular node, i.e., it does not match text, comments, attributes, and processing instructions.  

If we want to match text nodes we use the node-test `text().  

Similarly, we use `comment()` to match comments and `processing-instruction()` to match any processing instruction.   

If we want to match only processing instructions with a particular target, we pass the target name as a string in the call to `processing-instruction()`.  
```
//processing-instruction('R')
```

#### The Predicate  
Predicates allow us to further restrict the node-set, but they are not always needed and so can be omitted. A predicate tests each of the candidate nodes matched by the node-test part of the location step.  

**The XPath Location-step**  
XPath locates sets of nodes in XML documents. An XPath expression is a location path that is made up of one or more location steps. Each step has two required parts - the axis and node-test - and an optional predicate as the third part. The location step follows the syntax:  
```
axis::node-test[predicate]
```

The location step can be thought of as directions from one location (or context) to another. The direction is relative to each node in the current set of nodes, as computed by the previous step.  

The step indicates which direction to look (axis), the ndoe(s) name or type to locate (node-test), and the filter or subset condition to apply to the qualifying nodes (predicate).  

XPath ignores white space (blank spaces and new lines) within a location step and betwen steps which allows us to format the expressions freely.  

- `axis::` Orients the search and is expressed in the vocabulary of a tree hierarchy, e.g., `child` looks at the children of the current context, `parent` looks at the oarent, and `descendant-orself` looks at the current context and all nodes that descend from it. These axes are often abbreviated. For example, the `child` axis is the default and can be omitted entirely from the location step. Also, `descendant-or-self::foo` can be abbreviated to `//foo` and `attribute::name` can be expressed as `@name`. We can refer to the current node and the parent with `.` and `..`, rather than `self::node()` and `parent::node()`, respectively.  

- `node-test` Provides the element name or an element type to locate in the location step. For element with no names, e.g., text and comments, we use functions, such as `text()` and `comment()` to locate element by type. We can use the generic `node()` function to identity any regular/named node. The wildcard shortcut `*` also matches any regular node.  

- `[predicate]` This part of the location step operate on the nodes matching the `axis::node-test` and filters the qualifying nodes to those that meet the conditions of the predicate. The expression in the predicate is applied to each node in the node-test and if the result is `true`, the node remains in the node-set. XPath provides many functions to use in the predicate. For example, `[position() = last()]` keeps only the last node in the node-set; this can be abbreviated to `[last()`. Similary, we can subset by position, e.g., `//section[2]` yields the second <section> node. There are functions to compute the name or value of a node and also to perform string manipulation and comparisions. Simple expressions can be combined using the `and` & `or` operators.  
```
//Cube[currency = 'USD' or @rate > 1.5]

/descendant-or-self::Cube[@time]/child::Cube[attribute::rate<25]
```

More than one element can be located by an XPath expression. The located nodes are called the `node-set`. Each matching node appears in the node-set just once. This is useful and especially important to remember when we work with compound XPath queries.  


## XPath Functions and Logical Operators  
XPath provides logical operators for combining predicates. Predicates can be combined together into a compound predicate using one of the binary operators `and` or `or`.  
```
//Cube[@currency = 'JPY' or @currency = 'USD']
```

Other boolean operators in XPath include: `not()`, `true()`, and `false()`.  

The `not` operator is used to compute the opposite or negation of a condition. It is analogous to the `!` operator in R, and we can use it in an XPath expression such as  
```
//graphic[not (conditions(@fileref, '.jpg'))]
```
to find all <graphic> nodes that do not have a fileref attribute with the extension **jpg**. 


## Multiple Predicates in a Node Test  
**Expressions with Multiple Predicates**  
Predicates can be simple or compound and they can be nested, i.e., a predicate within a predicate. Additionally, predicates can appear on multiple location steps within an XPath expression or path, and a single location step can have multiple predicates, one after the other.  

- *Simple* A simple logical condition such as  
```
//Cube[@currency > 1.5]
//section[.//table]
```
to identify a <Cube> node that has a currency attribute value greater than 1.5 or a <section> node that contains a <table> element.  

- *Compound* Simple expressions combined using the operators `and` & `or`  
```
//Cube[@currency = 'USD' or @currency > 1.5]

and 

starts-with(., 'abc') and contains('xyz')
```

- *Nested* Two or more predicates nested within each other.  
```
//div[.//table[contains(string(./th), 'Price')]]
```
find an HTML <div> node that contains a table that contains the word `Price` in at least one of its column headers.  

- *Multiple location steps* Predicates can appear on the more than one location step in an XPath expression.  
```
/book/chapter/section[1]/para[3]
```
finds the third paragraph in the first section of each chapter in the book.  

- *Stacked* One predicate can follow another in a location step, which is called a stacked predicate. When this happens, the second predicate is evaluated in the context of the first.  
```
//section/para[code][2]
```
locates all paragraphs that contain code nodes and the second predicate selects the second of these paragraphs.  
```
//section/para[2][code]
```
first selects all paragraphs that are the second paragraph in a section; then the second predicate keeps those paragraphs that contain code.  


## Combining XPath Location Paths in a Single Query  
XPath allows us to combine multiple queries into a single query. We separate the individual queries using the |, with or without surrounding spaces.  
```{r}
doc <- xmlParse(file = "Data/DocBook/book.xml")
ti <- getNodeSet(doc = doc, "/book/bookinfo//title | /book/bookinfo/authorgroup/author/affiliation/orgname")
ti %>% xmlValue()
```


### Programmatically Generating XPath Queries in R  
```{r}
xpQueries <- c(section = "//section/title", 
               table = "/book/bookinfo//title", 
               figure = "/book/bookinfo/authorgroup/author/affiliation/orgname")

ti <- getNodeSet(doc, xpQueries[c("table", "figure")])
```

Importantly, by combining the two XPath queries, the nodes will be returned in the correct document order, i.e., the order in which the nodes appear in the document.  

```
//section//(table|figure)/title

or 

//section(//table|//figure)/title
```

### Programmatically Generating XPath Queries in R  
```{r}
xpQueries <- c(section = "//section/title", 
               table = "//section//table/title", 
               figure = "//section//figure/title")

ti <- getNodeSet(doc, xpQueries[c("table", "figure")])
```

```{r}
all.titles <- getNodeSet(doc, xpQueries)
```


```{r}
xpQueries <- sprintf("//section%s/title", 
                     c("", "//table", "//figure"))
```

```{r}
doc <- xmlParse(file = "Data/eurofxref-hist.xml")
currencies <- c("USD", "JPY", "BGN")
q <- sprintf("//Cube[@currency = '%s']", currencies)
exRate <- lapply(q, function(q) as.numeric(getNodeSet(doc, q)))
```

```{r}
doc <- xmlParse(file = "Data/Kiva/lenders/1.xml")
xpx <- "//lender/loan_count"
loanAmounts = as.numeric(xpathSApply(doc, xpx, xmlValue))

q <- sprintf("//lender[string(loan_count) > %.2f]", quantile(loanAmounts, 0.9))

bigLoans <- getNodeSet(doc, q)
```


**Combining Queries and Location Paths**  
Location paths can be combined using the `|` operator, where the expression on each side must be a valid location path.  
```
/book/chapter/section[1]/table | /book/chapter/section[1]/figure
```
locates all tables and figures in the first section of each chapter. We can combine any number of queries together, not just two.  

Complicated compound expressions may have nodes that match more than one subexpression.  

```
xpQ = c("//section[.//table]", "//section[.//figure])
getNodeSet(book, xpQ)
```

locates all sections that have either a table or figure in them in the parsed book object `book`. Sections that have both will appear once in the node-set and the sections will be in the order that they appear in the document.  


## Examples of Accessing Data with XPath  
```{r}
doc <- xmlParse(file = "Data/GovTrack/S. 2107 (Enrolled-Bill).xml")
xpx <- "/bill/legis-body/section/header"
xpathSApply(doc %>% xmlRoot, "//contain(bill)", xmlGetAttr, name = "number", default = NA)
xpathSApply(doc = doc, 
            path = xpx, 
            fun = xmlGetAttr, 
            name = "display-inline")
```


```{r}
doc <- xmlParse(file = "Data/merged_catalog.xml.gz")
xpx <- "/merge/event/param[@name = 'magnitude']"
magValues <- xpathSApply(doc = doc,
            path = xpx, 
            fun = xmlGetAttr, 
            name = "value") %>% 
    as.numeric()

magValues %>% table() %>% barplot(names.arg = NA)
```


```{r}
xpx <- "/merge/event/@time-stamp"
time_stamp <- getNodeSet(doc, xpx) %>% unlist()

# or 

time_stamp <- xpathSApply(doc = doc, 
                          path = "/merge/event", 
                          fun = xmlGetAttr, 
                          name = "time-stamp")
```


```{r}
doc <- xmlParse(file = "Data/Kiva/lenders/1.xml")
occ <- xpathSApply(doc = doc %>% xmlRoot, 
                   path = "//lender/occupation", 
                   fun = xmlValue)
occ %>% table() %>% sort(decreasing = T) %>% barplot(srt = 1, xlim = c(0, 50))
```

absolute path  
```{r}
doc <- xmlParse(file = "Data/JStatSoft/Lumley.xml")
xpx <- "/mods/name/namePart[@type = 'family']/text()"
getNodeSet(doc, xpx) %>% xmlValue()
```


relative path  
```{r}
xpx <- "//namePart[@type = 'family']/text()"
getNodeSet(doc, xpx) %>% xmlValue()
```

```{r}
doc <- xmlParse(file = "Data/JStatSoft/shortJStatSoft.xml")
xpx <- "//mods/name[1]/namePart[@type = 'family']/text()"
getNodeSet(doc, xpx) %>% xmlValue()
```

```{r}
xpx <- "//mods/name/namePart[@type='family' and position()  = 2]"
getNodeSet(doc, xpx) %>% xmlValue()
```

```{r}
xpx <- "//namePart[@type='family' and . = 'Narasimhan']"
getNodeSet(doc, xpx)
```

```{r}
xpx <- "//namePart[@type='family' and string(.) = 'Narasimhan']/ancestor::mods/name/namePart[@type = 'family']/text()"
getNodeSet(doc, xpx)
```

to find the co-authors family names but not the Narasimhan  
```{r}
xpx <- "//namePart[@type='family' and string(.) = 'Narasimhan']/ancestor::mods/name/namePart[@type = 'family' and not(./text() = 'Narasimhan')]/text()"

getNodeSet(doc, xpx)
```

```{r}
xpx <- "//namePart[@type='family' and ./text()='Narasimhan']/parent::name/preceding-sibling::name/namePart[@type='family']/text()|//namePart[@type='family' and ./text()='Narasimhan']/parent::name/following-sibling::name/namePart[@type='family']/text()"

getNodeSet(doc, xpx)
```

```{r}
q <- sprintf("//namePart[@type='family' and ./text()='%s']/parent::name/%s-sibling::name/namePart[@type='family']/text()", "Narasimhan", c("preceding", "following"))

getNodeSet(doc, q)
```

```{r}
xpathSApply(doc, q, xmlValue)
```

Rather than navigating down and then back up the hierarchy, it might be simplest to use a predicate to identify the different <mods> nodes of interest.  

```{r}
mods <- getNodeSet(doc, "/modsCollection/mods[./name/namePart[@type='family' and . = 'Narasimhan']]")
sapply(mods, function(x) xpathSApply(x, ".//namePart[@type='family']", xmlValue))
```

```{r}
mods <- getNodeSet(doc, "/modsCollection/mods[./name[1]/namePart[@type='family' and . = 'Narasimhan']]")
sapply(mods, function(x) xpathSApply(x, ".//namePart[@type='family']", xmlValue))
```

```{r}
xpx <- "//mods[name/namePart[@type='family' and string(.) = 'Lumley']]/identifier[@type='citekey']"
xpathSApply(doc, xpx, xmlValue)
```

Note that we can directly compare `.` (the `self` node) to the string `Lumley`. This is equivalent to calling `string(.)`, and since there is only one text child node of <namePart>, it is also equivalent to `string(text())` and `text()`.  


find the key for all articles written by Lumley  
```{r}
xpx <- "//mods/name/namePart[text() = 'Lumley']/ancestor::mods/identifier[@type='citekey']"
getNodeSet(doc, xpx)
```


## Namespace and XPath Queries  
A namespace has a URL that uniquely identifies it, and a prefix, which is what we work with locally our document.  

```{r}
doc <- xmlParse(file = "Data/sampleDoc.xml")
getNodeSet(doc = doc, 
           path = "//s:code", 
           namespaces = c(s = "http://www.r-project.org")) 
```

```{r}
Namespace <- c(x = 'http://docbook.org/ns/docbook', 
               r = 'http://www.r-project.org')
getNodeSet(doc = doc, 
           path = "//r:code", 
           namespaces = Namespace)
```


```{r}
doc <- xmlParse(file = "Data/eurofxref-hist.xml")
ns <- xmlNamespaces(doc, simplify = TRUE)
names(ns) == "" # the default element is TRUE
ns[names(ns) == ""]
```

```{r}
getDefaultNamespace(doc, simplify = T)
```

```{r}
doc <- xmlParse("Data/eurofxref-hist.xml")
getDefaultNamespace(doc, simplify = F)

getNodeSet(doc, "//Cube[@currency = 'NOK']")
```


## XInclude and XPointer  
XInclude and XPointer are two additional technologies and standards related to XML documents. These provide a rich way to insert the contents of part of a document within other documents.  

As a result, they facilitate modularity, reduce redundancy, and enable creation of complex descriptions and data structures within XML.  

**XInclude Structure**  
XInclude is a technology for merging XML fragments into a document. The XInclude namespace contains two elements: <include> and <fallback>. The <fallback> element is a child of <include> and provides a mechanism fro recovering from the inclusion of a missing resource and providing content to use when the content to be included is not available.  

- *href* Provides a URI reference for the location of the resource to include. When href is missing, the reference is to the same document and the xpointer attribute must be present and identify an element within the same document.  

- *xpointer* Identifies a portion of the resource to include. This attribute is optional; when ommitted, the entire resource is included. The attribute value is an XPointer expression that contains an XPath expression to identify the elements of interest in the target document. This XPointer expression can define namespace, as needed in the XPath expression.  

- *parse* Indicates whether to include the content/node-set as parsed XML (parse = 'xml') or as text(parse = 'text') directly and verbatim with no interpretation by the XML parser. The default value of this optional attribute is 'xml'.  

- *encoding* When `parse='text'`, the encoding attribute specifies the encoding of the resource.  


## Summary of FUnctions for Applying XPath Expressions to XML Documents  
- `getNodeSet()`  
- `xpathApply()`  
- `xpathSApply()`  
- `getDefaultNamespace()`  
- `xmlNamespaceDefinitions()`  


# Chapter 5 Strategies for Extracting Data from HTML and XML Content  
The DOM-based approaches assume we can read the entire XML document into memory and then process its contents. For very large documents, this is not practical. Instead, we have to process the XML content as we read it and convert those contents into R objects 'on the fly'. This involes a different, low-level processing model named SAX - Simple API for XML - that uses handler functions to respond to envents in the XML stream.  

When diccussing DOM parsing, we will introduce an approach that traverses the tree and extracts data using handler functions. This leads naturally to the lower-level SAX model.  

To work with XML in R, or any language, it is important to master these two skills - XPath and node manipulation.  

The SAX approach is quite different from the DOM approach as it does not try to build the XML tree. Instead, it passes small pieces of the document to 'handler' functions that the caller provides.  

SAX parsing is necessary for very large XML documents that would not easily fit in memory. The approch is more low-level and involes a different mindset and strategy from DOM parsing. Branches allows us to combine SAX and DOM approaches for small parts of the entire hierarchy.  


## Using High-level Functions to Read XML Content  
- `readHTMLTable()`  
- `xmlToDataFrame()`  
- `xmlToList()`  
- `readHTMLList()`  
- `getHTMLLinks()`  
- `getHTMLExternalFiles()`  
- `readHTMLTable()`  
- `readKeyValueDB()`  
- `readSolorDoc()`  


### Simple HTML Access  
All of these high-level functions allow the caller to specify the HTML document as  

- the name of a local file  
- a URL  
- the HTML content itself as a string  
- as an already parsed HTML document, i.e., an R object of class `HTMLInternalDocument`  


**getHTMLLinks()**  
```{r}
u <- "http://10.71.132.241/"
getHTMLLinks(doc = u, externalOnly = F, relative = T) %>% head()
```


**getHTMLExternalFiles()**  
```{r}
u <- "http://10.71.132.241/"
getHTMLExternalFiles(doc = u, recursive = T, relative = T)
```


### Extracting Data from HTML Tables  
```{r}
world_pop <- readHTMLTable(doc = "files/List of countries and dependencies by population - Wikipedia.html")
world_pop %>% class()
world_pop %>% length()
world_pop %>% lapply(dim)
world_pop <- readHTMLTable(doc = "files/List of countries and dependencies by population - Wikipedia.html", 
                           which = 1)

world_pop
```


```{r}
r <- regexec(pattern = "\\W", 
             text = world_pop$`Country (or dependent territory)`)
r %>% class()
r[[1]]
len <- length(world_pop$`Country (or dependent territory)`)
world_pop$`Country (or dependent territory)` <- substr(world_pop$`Country (or dependent territory)`, 1, ifelse(r > 0, as.numeric(r) - 1, len))
world_pop
```

```{r}
world_pop$Population <- gsub(",", "", world_pop$Population)
world_pop
```

```{r}
world_pop$`% of worldpopulation` <- gsub("%", "", world_pop$`% of worldpopulation`)
world_pop
```


```{r}
world_pop$Date <- as.character(world_pop$Date)
world_pop$Date <- strptime(x = world_pop$Date, 
                           format = "%e %b %Y")
world_pop$Date <- as.POSIXct(world_pop$Date)
world_pop
```

locate the table node then passing to the `readHTMLTable`  
```{r}
doc <- htmlParse(file = "files/List of countries and dependencies by population - Wikipedia.html")
getNodeSet(doc = doc, 
           path = "//table") %>% .[[1]] %>% 
    readHTMLTable()
```

```{r}
d <- readHTMLTable(doc = "files/History of the United States public debt - Wikipedia.html", 
                   which = 3, 
                   colClasses = c("integer", "Currency",  "Currency", "Percent",
                                  "Currency", "Currency", "Percent", "Currency", 
                                  "Currency", "Percent", "numeric"))
d <- d[-c(1, 2), ]
d
```

`XML` package defined classes  
- `integer`  
- `Currency`  
- `Percent`  
- `numeric`  
- `FormattedInteger`    
- `FormattedNumeric`  


### Extracting Other Information from HTML Table Cells  
The `readHTMLTable()` function allows us to extract different information from cells in the table by specifying our own function to process the cell node.  

```{r}
doc <- htmlParse(file = "files/List of countries and dependencies by population - Wikipedia.html")


getCellLink <- function(node){
    if(xmlName(node) == "td" && !is.null(node[["a"]]))
        xmlGetAttr(node[["a"]], "href", character())
    else
        character()
}
```


```{r}
htmlParse(file = "files/List of countries and dependencies by population - Wikipedia.html") %>% 
    getNodeSet(path = "//table[1]") %>% .[[1]] %>% 
    getHTMLLinks() %>% 
    head()
```


### Helper Functions for Converting Nodes  
- `xmlToList()`  
- `xmlToDataFrame()`  
- `xmlAttrsToDataFrame()`  


```{r}
doc <- xmlParse(file = "Data/JStatSoft/jstatsoft.xml")
mods <- getNodeSet(doc = doc, path = "//mods")
```


## Examples of Scraping Content from HTML Pages  
```{r}
doc <- htmlParse(file = "files/download.html")
xpx <- sprintf("//div[@class = 'css-debyuq e1voiwgp1']/h%d", 2:6) %>% paste(collapse = "|")
storyDivs <- getNodeSet(doc, xpx)
storyDivs %>% xmlSize()
```

```{r}
nyTimesRSSURL <- "files/HomePage.xml"
doc <- xmlParse(file = nyTimesRSSURL)
xpx <- "//item/title|//item/link|//item/description"
xpathSApply(doc = doc, 
            path = xpx, 
            fun = xmlValue) %>% 
    head()
```

```{r}
doc <- htmlParse(file = "files/Machine Learning and Data Science Job Openings | Kaggle.html")
links <- getHTMLLinks(doc = doc)
grep("/jobs/[:alnum:]{,5}", links, ignore.case = T, value = T)
```

```{r}
doc <- xmlParse(file = "files/inning_all.xml")
r <- xmlRoot(doc)
names(r) %>% table()
```

```{r}
xmlApply(r, names) %>% unlist() %>% table
```

```{r}
xpathApply(doc = doc, 
           path = "//inning/*", 
           fun = names) %>% 
    unlist() %>% 
    table()
```

```{r}
getNodeSet(doc = doc, 
           path = "//atbat/@num") %>% 
    as.integer()
```


```{r}
getNodeSet(doc = doc, path = "//pitch")[[1]]
```

```{r}
xpathSApply(doc = doc, 
            path = "//pitch", 
            fun = xmlGetAttr, 
            name = "id") %>% 
    as.integer()
```

```{r}
node_names <- xpathApply(doc = doc, 
           path = "//pitch", 
           function(node) {
               names(xmlAttrs(node = node))
           })

# all pitches have the same and equal number of attribute 
node_names %>% unlist() %>% table %>% table()

node_names[[1]]
```


```{r}
ats <- xpathApply(doc = doc, 
           path = "//pitch", 
           fun = function(x){
               a = xmlAttrs(x)
})

pitches <- function(list){
    df <- data.frame()
    for(i in seq_along(list)){
        x = as.data.frame(list[[i]], stringsAsFactors = F) %>% t()
        df <- rbind(df, x)
    }
    rownames(df) <- NULL
    return(df)
}

pitches(ats) %>% head()
```

```{r}
doc <- xmlParse(file = "Data/Kiva/lenders/1.xml")
lenderNodes <- xmlRoot(x = doc)[["lenders"]]
xmlSApply(lenderNodes, names) %>% unlist() %>% table()
```

create data frame for common variables  
```{r}
varNames <- c("lender_id", "loan_because", "name", "occupation")

vars <- lapply(varNames, 
       function(var){
           xp = sprintf("//lender/%s", var)
           xpathSApply(doc, xp, xmlValue)
       })

df <- vars %>% 
    as.data.frame(stringAsFactors = F) %>%
    magrittr::set_colnames(value = varNames)

df %>% dim()
```






















