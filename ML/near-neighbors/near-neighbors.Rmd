---
title: "near-neighbors"
author: "yincy"
date: "8/15/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, message=FALSE, warning=FALSE}
library(kknn)
library(Metrics)
library(magrittr)
```


# breast cancer
```{r}
cn <- c("Sample_ID", "Clump_Thickness", 
        "Cell_Size", "Cell_Shape", 
        "Marginal_Adhesion", "Epithelial_Cell_Size", 
        "Bare_Nuclei", "Bland_Chromatin", 
        "Normal Nucleoli", "Mitoses", 
        "Class")
cc <- rep("factor", length(cn))
brca <- read.table("/home/yincy/git/Data/ML/breat-cancer/breast-cancer-wisconsin.data", 
                   sep = ",", 
                   header = F, 
                   na.strings = "?", 
                   col.names = cn, 
                   colClasses = cc)

brca <- na.omit(brca)
brca <- brca[, -1]
brca %>% str
```

## test the accuracy on the train dataset
```{r}
set.seed(111)
len <- dim(brca)[1]
train_id <- sample(len, size = 2/3 * len, replace = F)
brca_knn <- kknn(formula = Class ~., 
                 train = brca[train_id, ], 
                 test = brca[train_id, ])
predicted_train <- brca_knn$fitted.values

# classification error
Metrics::ce(brca[train_id, "Class"], predicted_train)

# accuracy of classification
Metrics::accuracy(brca[train_id, "Class"], predicted_train)

table(prediction = brca_knn$fitted.values, real = brca[train_id, "Class", drop = T]) 
```

## test the accuracy on the test dataset
```{r}
brca_knn <- kknn(Class ~., 
                 train = brca[train_id, ], 
                 test = brca[-train_id, ])

predicted_test <- brca_knn$fitted.values

# classification error
Metrics::ce(actual = brca[-train_id, "Class"], 
            predicted = predicted_test)

# accuracy of classification
Metrics::accuracy(actual = brca[-train_id, "Class"], 
                  predicted = predicted_test)

table(predicted = predicted_test, 
      real = brca[-train_id, "Class"])
```

## model optimization
find the optimal kernel and k
```{r}
brca_kk <- train.kknn(
  formula = Class ~., 
  data = brca, 
  kmax = 100, 
  kernel = c("rectangular", "epanechnikov", 
             "biweight", "cos", 
             "gaussian", "optimal")
)

brca_kk
```

```{r}
best_k <- brca_kk$best.parameters$k
best_kernel <- brca_kk$best.parameters$kernel

ce_kk <- brca_kk$MISCLASS %>% 
  as.data.frame() %>% 
  tibble::rownames_to_column("K") %>% 
  tidyr::gather(key = "kernel", value = "ce", -K) %>% 
  dplyr::mutate(K = as.integer(K))
min_ce <- min(ce_kk$ce)

library(ggplot2)
ce_kk %>% 
  ggplot(aes(K, ce)) +
  geom_line(aes(color = kernel)) +
  geom_point(aes(color = kernel), size = 1) +
  geom_vline(xintercept = best_k, linetype = "dashed", size = 0.3) +
  geom_hline(yintercept = min_ce, linetype = "dashed", size = 0.3)
```

## kfold cross validation
```{r}
set.seed(1111)
rindex <- sample(dim(brca)[1])
f <- rep(1:10, length.out = dim(brca)[1]) %>% sample
kflods <- split(rindex, f = f)
ce_train <- vector(mode = "numeric", length = length(kflods))
ce_test <- vector(mode = "numeric", length = length(kflods))

for(i in 1:length(kflods)){
  curr_fold <- kflods[[i]]
  train_set <- brca[curr_fold, ]
  test_set <- brca[-curr_fold, ]
  predicted_train <- kknn(
    Class ~., 
    train = train_set, 
    test = train_set,
    k = best_k, 
    kernel = best_kernel
  )$fitted.values
  ce_train[[i]] <- Metrics::ce(train_set$Class, predicted_train)
  
  predicted_test <- kknn(
    Class ~., 
    train = train_set, 
    test = test_set, 
    k = best_k, 
    kernel = best_kernel
  )$fitted.values
  ce_test[[i]] <- Metrics::ce(test_set$Class, predicted_test)
}


df <- data.frame(k = 1:10, 
                 train = ce_train, 
                 test = ce_test) %>% 
  tidyr::gather(key = "type", value = "error_rate", -k)
```

```{r}
df %>% 
  ggplot(aes(k, error_rate)) +
  geom_line(aes(color = type)) +
  geom_point(aes(color = type)) +
  scale_x_continuous(breaks = seq(1, 11, 2))
```









